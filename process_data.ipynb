{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0058d880",
   "metadata": {},
   "source": [
    "# Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaaaee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:09:45.457694Z",
     "start_time": "2024-03-28T19:09:44.944807Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "from copy import copy, deepcopy\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "path.append( str(Path.cwd().parent) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f0558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:09:47.917281Z",
     "start_time": "2024-03-28T19:09:46.441684Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from string import punctuation, whitespace\n",
    "\n",
    "from Project_libraries.my_stats import ( place_commas )\n",
    "\n",
    "from Project_libraries.pubmed import ( concatenate_lines, \n",
    "                                       get_articles_start_line,\n",
    "                                       extract_publication_date, \n",
    "                                       get_article_data,\n",
    "                                       classify_articles )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e81ff",
   "metadata": {},
   "source": [
    "# Import and process data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a87ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:09:51.581633Z",
     "start_time": "2024-03-28T19:09:51.552120Z"
    }
   },
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "aux = cwd.glob('Case_*')\n",
    "\n",
    "cases = []\n",
    "for case in aux:\n",
    "    cases.append( case.parts[-1] )\n",
    "    \n",
    "cases.sort()\n",
    "\n",
    "for i in range(len(cases)):\n",
    "    print(f\"{i:>2} -- {cases[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4ecd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:12:39.666113Z",
     "start_time": "2024-03-28T19:12:39.514899Z"
    }
   },
   "outputs": [],
   "source": [
    "case = cases[10]\n",
    "print(f\"We will be processing the data in folder '{case}'.\\n\")\n",
    "\n",
    "case_folder = cwd / case\n",
    "abstracts_files = list( case_folder.glob( 'abstract-*.txt' ) )\n",
    "\n",
    "\n",
    "print(f\"The files to be read are:\")\n",
    "for x in abstracts_files:\n",
    "    print(f\"\\t* {x.parts[-1]}\")\n",
    "    \n",
    "print('\\n'*2)\n",
    "    \n",
    "articles_start, data = get_articles_start_line( abstracts_files )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1a7a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T19:45:42.671779Z",
     "start_time": "2024-03-21T19:45:42.646808Z"
    }
   },
   "source": [
    "## Highlight retracted articles and articles that fail to process\n",
    "\n",
    "**NOTE: If alert about Copyright Surprise prints two lines and the first one\n",
    "is the correct copyright, then this is not a problem!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae9bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:12:46.007535Z",
     "start_time": "2024-03-28T19:12:45.630427Z"
    }
   },
   "outputs": [],
   "source": [
    "articles = []\n",
    "retracted_articles = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in range(0, len(articles_start) - 1):\n",
    "#     print(articles_start[i],articles_start[i+1])\n",
    "    info = copy( data[articles_start[i]:articles_start[i+1]])\n",
    "    \n",
    "    try:\n",
    "        flag, article = get_article_data(i, info)\n",
    "        \n",
    "        if flag:\n",
    "            retracted_articles.append( article )\n",
    "    \n",
    "        articles.append( article )\n",
    "\n",
    "    except IndexError:\n",
    "        count1 += 1\n",
    "        print( f\"{count1} -- Article {i+1}, lines {articles_start[i]} to \"\n",
    "               f\"{articles_start[i+1]} failed to process\" )\n",
    "        articles.append( None )\n",
    "        \n",
    "    except ValueError:\n",
    "        count2 += 1\n",
    "        print( f\"{count2} -- Article {i+1}, lines {articles_start[i]} to \"\n",
    "               f\"{articles_start[i+1]} lacks year.\" )\n",
    "        articles.append( None )\n",
    "        \n",
    "    except:\n",
    "        print( f\"Article {i+1}, lines {articles_start[i]} to \"\n",
    "               f\"{articles_start[i+1]}.\" )\n",
    "        flag, article = get_article_data(info)\n",
    "        \n",
    "    \n",
    "print(f\"\\n----> There are {place_commas(len(articles))} articles for analysis.\\n\\n\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3cb755",
   "metadata": {},
   "source": [
    "## Check output for problematic record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d3831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:34:37.049697Z",
     "start_time": "2024-03-28T18:34:37.012650Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 1940\n",
    "print(articles_start[i],articles_start[i+1])\n",
    "print()\n",
    "info = copy( data[articles_start[i]:articles_start[i+1]])\n",
    "print(info)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "flag, article = get_article_data(i, info)\n",
    "print()\n",
    "print()\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b505d6",
   "metadata": {},
   "source": [
    "# Verify records\n",
    "\n",
    "The function call implements manual corrections to problematic articles.\n",
    "\n",
    "**If this cell print anything, it means that some articles are not processed correctly.**\n",
    "\n",
    "This may be fixable within function or require a manual correction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ddd03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:12:51.892073Z",
     "start_time": "2024-03-28T19:12:51.862570Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test for errors\n",
    "for i, article in enumerate( articles ):\n",
    "    if article:\n",
    "        if ( article['other_ids'][:3] == 'DOI' \n",
    "             or article['other_ids'][:4] == 'PMID' \n",
    "             or article['other_ids'][:5] == 'PMCID' ):\n",
    "            continue\n",
    "        \n",
    "        print(i, article['other_ids'], '\\n')\n",
    "        \n",
    "\n",
    "print(f\"There are {place_commas(len(articles))} articles for analysis.\\n\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ffec8",
   "metadata": {},
   "source": [
    "## Check output for problematic record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63faa5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T16:56:32.701569Z",
     "start_time": "2024-03-26T16:56:32.679987Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 25\n",
    "info = copy(data[articles_start[i]:\n",
    "                 articles_start[i+1]])\n",
    "\n",
    "for line in info:\n",
    "    print(line.strip())\n",
    "print()\n",
    "\n",
    "# for line in concatenate_lines(info):\n",
    "#     print(line.strip())\n",
    "#     print()\n",
    "\n",
    "print('------')\n",
    "print(get_article_data(info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358bbaf",
   "metadata": {},
   "source": [
    "# Clean article data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d264c14",
   "metadata": {},
   "source": [
    "## Remove articles reporting retractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdad0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:12:57.566414Z",
     "start_time": "2024-03-28T19:12:57.538116Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "for i, article in enumerate( articles ):\n",
    "    if article and article['retraction']:\n",
    "        print( f\"{i} -- {article['journal']}. {article['year']}; {article['volume']} \" \n",
    "               f\"\\n\\t{article['title']}\\n\\t{article['retraction']}\\n\")\n",
    "        if article['retraction'][:19] == 'Retraction Notice: ':\n",
    "            to_remove.append(i)\n",
    "            print(to_remove)\n",
    "\n",
    "print(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0842b84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:10.390365Z",
     "start_time": "2024-03-28T19:13:10.358512Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in reversed(to_remove):\n",
    "    articles.pop(i)\n",
    "\n",
    "print(f\"There are {place_commas(len(articles))} articles left for for analysis.\\n\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91d0ea",
   "metadata": {},
   "source": [
    "## Remove errata, i.e., articles reporting corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f788bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:13.332901Z",
     "start_time": "2024-03-28T19:13:13.305034Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "for i, article in enumerate( articles ):\n",
    "    if article and article['erratum']:\n",
    "        print( f\"{i} -- {article['journal']}. {article['year']}; {article['volume']} \" \n",
    "               f\"\\n\\t{article['title']}\\n\\t{article['erratum']}\\n\")\n",
    "        if article['erratum'][:12] == 'Erratum for ':\n",
    "            to_remove.append(i)\n",
    "            print(to_remove)\n",
    "            \n",
    "print(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef30ed6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:18.730417Z",
     "start_time": "2024-03-28T19:13:18.704454Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in reversed(to_remove):\n",
    "    articles.pop(i)\n",
    "\n",
    "print(f\"There are {place_commas(len(articles))} articles left for for analysis.\\n\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c71fee",
   "metadata": {},
   "source": [
    "## Remove comments\n",
    "\n",
    "**Dealing with *Comments* is complicated!**\n",
    "\n",
    "Some *Comments* are perspectives aiming to publicize the target paper (like News & Views in Nature). These are published in the same issue by different authors.\n",
    "\n",
    "We remove the actual *Comment* (if available) from the set of publications to analyze. We adjust `comment` key of target paper to convey this positive information. \n",
    "\n",
    "Some *Comments* appear to be summaries of the target papers. They are published in a different journal by a subset of the original authors.\n",
    "\n",
    "We remove the actual *Comment* (if available) from the set of publications to analyze. We adjust `comment` key of target paper to convey this information. \n",
    "\n",
    "Some *Comments* appear to be actual criticisms of the target papers. They are published in the same journal as the target bu later than the target and are authored by different researchers.\n",
    "\n",
    "We remove the actual *Comment* (if available) from the set of publications to analyze. We adjust `comment` key of target paper to convey this negative information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac578e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:23.379778Z",
     "start_time": "2024-03-28T19:13:23.321762Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "for i, article in enumerate( articles[:] ):\n",
    "    if article and article['comment']:\n",
    "        print('\\n', i, 'Focus: ', article['journal'], article['year'], \n",
    "              article['date'], article['volume'],  \n",
    "              article['pages'], article['doi'])\n",
    "        print('--', article['comment'])\n",
    "        \n",
    "        # Extract info about paper discussed in comment\n",
    "        target = {}\n",
    "        aux = article['comment'].split(';')\n",
    "        if len(aux) == 1:\n",
    "            to_remove.append(i)\n",
    "            continue\n",
    "    \n",
    "        aux = aux[0].split('.')\n",
    "        date_string =  aux[-1].strip()\n",
    "        if len(date_string) < 4:\n",
    "            to_remove.append(i)\n",
    "            continue\n",
    "\n",
    "        # The code would otherwise fail if there is no period after journal name\n",
    "        #\n",
    "        try:\n",
    "            target['year'] = int( date_string[:4] )\n",
    "            target['date'] = date_string[4:]\n",
    "        except ValueError:\n",
    "            to_remove.append(i)\n",
    "            continue\n",
    "            \n",
    "        target['journal'] = aux[-2].strip()\n",
    "        \n",
    "        aux = article['comment'].split(';')[1]\n",
    "        aux = aux.split(':')\n",
    "        target['volume'] = aux[0]\n",
    "        target['pages'] = aux[1].split('.')[0]\n",
    "        \n",
    "        if len(aux) > 2:\n",
    "            target['doi'] = aux[2].split()[0].strip('.')\n",
    "        else:\n",
    "            target['doi'] = None\n",
    "          \n",
    "        # Extract dates of publication\n",
    "        date_focus = extract_publication_date(article)\n",
    "        date_target = extract_publication_date(target)\n",
    "        \n",
    "        # Determine type of comment\n",
    "        #\n",
    "        # Same journal\n",
    "        print(article['journal'])\n",
    "        print(target['journal'].lstrip('Coment').strip().lstrip('ion').strip())\n",
    "        if ( article['journal'] == \n",
    "             target['journal'].lstrip('Coment').strip().lstrip('ion').strip() ):\n",
    "            print('===>>', article['journal'])\n",
    "            print('===>>', article['year'], target['year'])\n",
    "            \n",
    "            # Same year \n",
    "            if article['year'] == target['year']:\n",
    "                print('===>>', article['volume'], target['volume'])\n",
    "            \n",
    "                # Same volume\n",
    "                if target['volume'] and article['volume'] == target['volume']:\n",
    "                    print('--->', article['date'], target['date'])\n",
    "                    \n",
    "                    # Same date\n",
    "                    if article['date'] == target['date']:\n",
    "                        print('--->', article['date'])\n",
    "\n",
    "                        if '-' in article['pages']:\n",
    "                            focus_pages = article['pages'].split('-')[0]\n",
    "                            if focus_pages.isnumeric():\n",
    "                                focus_pages = int(focus_pages)\n",
    "                        else:\n",
    "                            focus_pages = article['pages']\n",
    "                            \n",
    "                        if '-' in target['pages']:\n",
    "                            target_pages = target['pages'].split('-')[0]\n",
    "                            if target_pages.isnumeric():\n",
    "                                target_pages = int(target_pages)\n",
    "                        else:\n",
    "                            target_pages = target['pages']\n",
    "                            \n",
    "                        if type(target_pages) != type(focus_pages):\n",
    "                            target_pages = str(target_pages)\n",
    "                            focus_pages = str(focus_pages)\n",
    "\n",
    "                        print('--->', focus_pages, target_pages)\n",
    "                        \n",
    "                        # Same date, earlier pages\n",
    "                        if focus_pages < target_pages:\n",
    "                            to_remove.append(i)\n",
    "                            print(f\"---> Article {i} is a commentary and is to be removed\")\n",
    "\n",
    "                        # Same date, later pages\n",
    "                        else:\n",
    "                            article['comment'] = ('Received highlight article! ' \n",
    "                                                  + article['comment'])\n",
    "                            print('---> Received highlight article\\n')\n",
    "\n",
    "                    # Same volume, later time\n",
    "                    elif article['date'] > target['date']:\n",
    "                        to_remove.append(i)\n",
    "                        print(f\"---> Article {i} is a comment and is to be removed\")\n",
    "\n",
    "                    # Same volume, earlier time\n",
    "                    elif article['date'] < target['date']:\n",
    "                        article['comment'] = 'Received comment! ' + article['comment']\n",
    "                        print('---> Received comment\\n')\n",
    "\n",
    "                # Same year, volumes that exist, later volume\n",
    "                elif ( target['volume'] and article['volume'] and \n",
    "                       article['volume'] > target['volume'] ):\n",
    "                    to_remove.append(i)\n",
    "                    print(f\"---> Article {i} is a comment and is to be removed\")\n",
    "                \n",
    "                # Same year, volumes that exist, earlier volume\n",
    "                elif ( target['volume'] and article['volume'] and \n",
    "                       article['volume'] < target['volume'] ):\n",
    "                    article['comment'] = 'Received comment! ' + article['comment']\n",
    "                    print('---> Received comment\\n')\n",
    "\n",
    "                # Same journal, same year, missing volumes \n",
    "                else:\n",
    "                    # Same journal, same year, missing volumes, same date\n",
    "                    if article['date'] == target['date']:\n",
    "                        print('--->', article['date'])\n",
    "\n",
    "                        if '-' in article['pages']:\n",
    "                            focus_pages = article['pages'].split('-')[0]\n",
    "                            if focus_pages.isnumeric():\n",
    "                                focus_pages = int(focus_pages)\n",
    "                        if '-' in target['pages']:\n",
    "                            target_pages = target['pages'].split('-')[0]\n",
    "                            if target_pages.isnumeric():\n",
    "                                target_pages = int(target_pages)\n",
    "\n",
    "                        print('--->', focus_pages, target_pages)\n",
    "\n",
    "                        # Same journal, same year, missing volumes, same date, earlier pages\n",
    "                        if focus_pages < target_pages:\n",
    "                            to_remove.append(i)\n",
    "                            print(f\"---> Article {i} is a commentary and is to be removed\")\n",
    "\n",
    "                        # Same journal, same year, missing volumes, same date, earlier pages\n",
    "                        else:\n",
    "                            article['comment'] = ('Received highlight article! ' \n",
    "                                                  + article['comment'])\n",
    "                            print('---> Received highlight article\\n')\n",
    "        \n",
    "                    # Same journal, same year, missing volumes, later time\n",
    "                    elif article['date'] > target['date']:\n",
    "                        to_remove.append(i)\n",
    "                        print(f\"---> Article {i} is a comment and is to be removed\")\n",
    "\n",
    "                    # Same journal, same year, missing volumes, earlier time\n",
    "                    elif article['date'] < target['date']:\n",
    "                        article['comment'] = 'Received comment! ' + article['comment']\n",
    "                        print('---> Received comment\\n')\n",
    "        \n",
    "            # Same journal, later year \n",
    "            elif article['year'] > target['year']:\n",
    "                to_remove.append(i)\n",
    "                print(f\"---> Article {i} is a comment and is to be removed\")\n",
    "\n",
    "            # Same journal, earlier year\n",
    "            elif article['year'] < target['year']:\n",
    "                article['comment'] = 'Received comment! ' + article['comment']\n",
    "                print('---> Received comment\\n')\n",
    "\n",
    "\n",
    "        # Different journals, later year\n",
    "        elif article['year'] > target['year']:\n",
    "            to_remove.append(i)\n",
    "            print(f\"---> Article {i} is a commentary and is to be removed\")\n",
    "\n",
    "        # Different journals, earlier year\n",
    "        elif article['year'] < target['year']: \n",
    "            article['comment'] = 'Received commentary! ' + article['comment']\n",
    "            print('---> Received commentary\\n')\n",
    "\n",
    "        # Different journals, same year\n",
    "        else:\n",
    "            if date_focus > date_target:\n",
    "                to_remove.append(i)\n",
    "                print(f\"---> Article {i} is a commentary and is to be removed\")\n",
    "            \n",
    "            elif date_focus <= date_target:\n",
    "                article['comment'] = 'Received commentary! ' + article['comment']\n",
    "                print('---> Received commentary\\n')\n",
    "                \n",
    "            else:\n",
    "                print( Style.BRIGHT, Fore.RED,'----------RED ALERT!!!---------', \n",
    "                       Style.RESET_ALL )\n",
    "\n",
    "print(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90db248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:27.987526Z",
     "start_time": "2024-03-28T19:13:27.958939Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in reversed(to_remove):\n",
    "    articles.pop(i)\n",
    "\n",
    "print(f\"There are {place_commas(len(articles))} articles left for for analysis.\\n\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab6120",
   "metadata": {},
   "source": [
    "## Remove articles with no information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc38f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:31.591373Z",
     "start_time": "2024-03-28T19:13:31.564285Z"
    }
   },
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "\n",
    "for i, article in enumerate( articles ):\n",
    "    if article is None:\n",
    "        to_remove.append(i)\n",
    "        \n",
    "print(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ec7b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:34.623479Z",
     "start_time": "2024-03-28T19:13:34.593775Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in reversed(to_remove):\n",
    "    articles.pop(i)\n",
    "\n",
    "print(f\"There are {place_commas(len(articles))} articles left for for analysis.\\n\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c7ddf",
   "metadata": {},
   "source": [
    "## Count number of articles of different types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a9035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:37.588911Z",
     "start_time": "2024-03-28T19:13:37.559927Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = classify_articles( articles, case )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ea259",
   "metadata": {},
   "source": [
    "# Save cleaned article data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04daabe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:13:40.838193Z",
     "start_time": "2024-03-28T19:13:40.730640Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(case_folder / 'articles_clean.json', 'w', encoding = 'utf-8') as f_json:\n",
    "    json.dump(articles, f_json)\n",
    "    \n",
    "print('Done saving file!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c39ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd8dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f9343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684dcec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce31e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21339d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c694cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66125bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dc28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93cbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3945309f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98eef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff5bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840ff5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce741c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b41d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a495c09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:26:33.118908Z",
     "start_time": "2024-03-26T18:26:33.087692Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for article in articles:\n",
    "    if article['copyright']:\n",
    "        temp.append(article['copyright'][:5])\n",
    "    \n",
    "print(sorted(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d97866",
   "metadata": {},
   "outputs": [],
   "source": [
    "['©', '(c)', 'Copyright', 'All rights', \n",
    " 'Published by', 'Published on behalf', 'Published under',\n",
    " 'AG', 'A.G.', 'BV', 'B.V.', 'GmbH', 'Inc', 'LLC', 'Ltd', 'S.A.U.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f8c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482bb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if ( '©' in info[5] or 'Copyright' in info[5]  \n",
    "         or 'All rights reserved' in info[5] \n",
    "         or 'Published by' in info[5] \n",
    "         or 'Verlag KG' in info[5] \n",
    "         or 'Wiley-Liss, Inc.' in info[5] \n",
    "         or 'John Wiley & Sons' in info[5] \n",
    "         or 'Wiley Periodicals, Inc' in info[5]\n",
    "         or 'wileyonlinelibrary.com/journal/jgc4' in info[5]\n",
    "         or 'Thieme' in info[5] \n",
    "         or 'Thieme Medical Publishers' in info[5] \n",
    "         or '(Cancer Epidemiol Biomarkers Prev' in info[5]\n",
    "         or 'American Cancer Society' in info[5] \n",
    "         or 'Massachusetts Medical Society' in info[5]\n",
    "         or 'BMJ Publishing Group Ltd' in info[5]\n",
    "         or 'Celsius' in info[5]\n",
    "         or 'Karger AG' in info[5] \n",
    "         or 'APA' in info[5] \n",
    "         or 'RSNA' in info[5]\n",
    "         or 'AACR' in info[5] \n",
    "         or 'Multimed Inc' in info[5]\n",
    "         or 'in the public domain' in info[5]\n",
    "         or 'Creative Commons Attribution' in info[5]\n",
    "         or 'Radiological Society of North America, Inc' in info[5]\n",
    "         or 'American Institute of Chemical Engineers Biotechnol' in info[5] \n",
    "         or 'American Academy of Family Physicians'  in info[5] ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140fdafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "#         article['copyright'] = info[5].strip(punctuation + whitespace)\n",
    "#         article['other_ids'] = info[6]\n",
    "#         m = 6\n",
    "#     else:\n",
    "#         article['copyright'] = None\n",
    "#         article['other_ids'] = info[5]\n",
    "#         m = 5\n",
    "        \n",
    "#     # Check for error due to abstract in foreign language\n",
    "#     if article['other_ids'][:10] == 'Publisher:' or len(article['other_ids']) > 300:\n",
    "#         if article['abstract']:\n",
    "#             article['abstract'] += ' ' + article['other_ids']\n",
    "#         else:\n",
    "#             article['abstract'] = article['other_ids']\n",
    "            \n",
    "#         if ( '©' in info[m+1] or 'Copyright' in info[m+1]  \n",
    "#              or 'All rights reserved' in info[m+1] \n",
    "#              or 'Published by' in info[m+1] \n",
    "#              or 'Verlag KG' in info[m+1] \n",
    "#              or 'Wiley-Liss, Inc.' in info[m+1] \n",
    "#              or 'John Wiley & Sons' in info[m+1] \n",
    "#              or 'Wiley Periodicals, Inc' in info[m+1]\n",
    "#              or 'wileyonlinelibrary.com/journal/jgc4' in info[m+1]\n",
    "#              or 'Thieme' in info[m+1]\n",
    "#              or 'Thieme Medical Publishers' in info[m+1]\n",
    "#              or '(Cancer Epidemiol Biomarkers Prev' in info[m+1]\n",
    "#              or 'American Cancer Society' in info[m+1]\n",
    "#              or 'Massachusetts Medical Society' in info[m+1]\n",
    "#              or 'BMJ Publishing Group Ltd' in info[m+1]\n",
    "#              or 'Celsius' in info[m+1]\n",
    "#              or 'Karger AG' in info[m+1] \n",
    "#              or 'APA' in info[m+1]\n",
    "#              or 'RSNA' in info[m+1]\n",
    "#              or 'AACR' in info[m+1]\n",
    "#              or 'Multimed Inc' in info[m+1]\n",
    "#              or 'in the public domain' in info[m+1]\n",
    "#              or 'Creative Commons Attribution License' in info[m+1]\n",
    "#              or 'Radiological Society of North America, Inc' in info[m+1]\n",
    "#              or 'American Institute of Chemical Engineers Biotechnol' in info[m+1] \n",
    "#              or 'American Academy of Family Physicians'  in info[m+1] ):\n",
    "#             article['copyright'] = info[m+1].strip(punctuation + whitespace)\n",
    "#             article['other_ids'] = info[m+2]\n",
    "#         else:\n",
    "#             article['copyright'] = None\n",
    "#             article['other_ids'] = info[m+1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new_base] *",
   "language": "python",
   "name": "conda-env-new_base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
